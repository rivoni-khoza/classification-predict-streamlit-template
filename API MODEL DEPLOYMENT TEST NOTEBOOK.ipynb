{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the Text Data\n",
    "import nltk\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as  plt\n",
    "import seaborn as sns\n",
    "import re \n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "\n",
    "# Model building\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and assigning a variable to the train dataset\n",
    "df_train = pd.read_csv('train_6.csv', skipinitialspace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the train dataset.\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset Cleaning Function\n",
    "def CleanTweets(tweets):\n",
    "    # Converts from upper case to lower case\n",
    "    tweets = tweets.lower()\n",
    "    # removes the rt and wired strings at the begining of tweets\n",
    "    tweets = tweets.replace('rt','')\n",
    "    tweets = tweets.replace('wired','')\n",
    "    # remove emojis\n",
    "    tweets = tweets.replace('[^A-Za-z0-9]','')\n",
    "    # removing numbers\n",
    "    tweets = re.sub(r'\\d+','',tweets)\n",
    "    # removes @ mentions \n",
    "    tweets = re.sub('@[\\w]*','',tweets)\n",
    "    # removes urls\n",
    "    tweets = re.sub(r'https?:\\/\\/.*\\/\\w*','',tweets)\n",
    "    # removes hashtags\n",
    "    tweets = re.sub(r'#\\w*','',tweets)\n",
    "    # removes punctuation\n",
    "    tweets = ''.join([l for l in tweets if l not in string.punctuation])   \n",
    "    # removes funny diamond\n",
    "    tweets = re.sub(r\"U+FFFD \",'', tweets)\n",
    "    # Removes extra white space\n",
    "    tweets = re.sub(r'\\s\\s+','',tweets)\n",
    "    # removes the newline characters [\\n] from pandas column\n",
    "    tweets = tweets.replace('\\n', ' ')\n",
    "    # removes space infront of tweet\n",
    "    tweets = tweets.strip()\n",
    "\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the Dataset Cleaning Function\n",
    "df_train['message'] = df_train['message'].apply(CleanTweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>researchers say we have three years to act on ...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>was a pivotal year in the war on climate change</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>itsand a racist sexist climate change denying ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   625221\n",
       "1          1  its not like we lack evidence of anthropogenic...   126103\n",
       "2          2  researchers say we have three years to act on ...   698562\n",
       "3          1    was a pivotal year in the war on climate change   573736\n",
       "4          1  itsand a racist sexist climate change denying ...   466954"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the Train Dataset after Cleaning\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     polyscimajor epa chief doesnt think carbon dio...\n",
       "1     its not like we lack evidence of anthropogenic...\n",
       "2     researchers say we have three years to act on ...\n",
       "3       was a pivotal year in the war on climate change\n",
       "4     itsand a racist sexist climate change denying ...\n",
       "5     woh a read whether you do or dont believe in c...\n",
       "6     mike pence doesn’t believe in global warming o...\n",
       "7     six big things we can all do today to fight cl...\n",
       "8     my yo nephew is inconsolable he wants to die o...\n",
       "9     no offense… but like… how do you just not beli...\n",
       "10    shes thinking about how shes going to die beca...\n",
       "11    i do hope people who are vocal about climate c...\n",
       "12    we only have apercent chance of avoiding ‘dang...\n",
       "13    oh my godtrumps government removes climate cha...\n",
       "14    fossil fuel giant exxonmobil ‘misled’ the publ...\n",
       "15    i dont wanna live forever – and nothing will b...\n",
       "16    issues scrubbed fromtoday civil rights climate...\n",
       "17    if our elected leaders fail to approach the en...\n",
       "18    we have a presidentelect who doesnt believe in...\n",
       "19    calum tweets abt reunitingish w the cast sees ...\n",
       "20    c mayors representing m citizens have urged g ...\n",
       "21                  how climate change impacts wildlife\n",
       "22    we also met this guy he let us in on some trut...\n",
       "23    scientists say climate change wiped out an ent...\n",
       "24    obama raises climate change you better vote fo...\n",
       "25    i hate to say this but mental health will be p...\n",
       "26        bangladesh confronting climate change head on\n",
       "27    hey there michaels vetted and approved marketb...\n",
       "28    sally kohn’s latest evidence of climate change...\n",
       "29    first the public understands climate change be...\n",
       "30    are these the same scientists that denounce cl...\n",
       "31    a guide to global warming paris pact and the u...\n",
       "32    atmospheric rivers fueled by climate change co...\n",
       "33         denying climate change ignores basic science\n",
       "34    bgrchina practically says trump lied about cli...\n",
       "35    the future of the planet is at stake hillary c...\n",
       "36    trumps team removed climate change data from t...\n",
       "37    toxic soils aquifers vast amts of wastedwaste ...\n",
       "38    america where climate change is “unproven” to ...\n",
       "39    we’ ve dealt with simple issues like climate c...\n",
       "40    they protested in suppo of climate change at t...\n",
       "41    climate targets nations are playing the long g...\n",
       "42    trumps climate change denial could cost ustril...\n",
       "43    win probability is bullshit man i saw the nba ...\n",
       "44    the alaskan tundra is filling the atmosphere w...\n",
       "45    fromindian environmentalist calls out dicaprio...\n",
       "46    carbon tax is a globalist idea to enslave the ...\n",
       "47    will anyone who suppos trumps view of climate ...\n",
       "48    we had winds close tomph in the area this afte...\n",
       "49    world food supplies at risk aschange threatens...\n",
       "50    macron my charm may have changed trumps mind o...\n",
       "51    shes thinking about how shes going to die beca...\n",
       "52    chris who is it then that initially talked abo...\n",
       "53    do you approve of the executive orderis due to...\n",
       "54    trump doesnt believe in global warming and hes...\n",
       "55    irony florida a state in danger of being washe...\n",
       "56    lmao 😂 snowflakes ❄️ complaining about snowfla...\n",
       "57    this is one of arnold schwarzeneggers vehicles...\n",
       "58    they are calling to the great space cylinder t...\n",
       "59    pollution from india and china has reached the...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the Messages Column after Cleaning\n",
    "df_train['message'].head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the messages column and adding the result to new [Tokenized messages] column\n",
    "df_train['Tokenized messages'] = df_train['message'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [polyscimajor, epa, chief, doesnt, think, carb...\n",
       "1    [its, not, like, we, lack, evidence, of, anthr...\n",
       "2    [researchers, say, we, have, three, years, to,...\n",
       "3    [was, a, pivotal, year, in, the, war, on, clim...\n",
       "4    [itsand, a, racist, sexist, climate, change, d...\n",
       "Name: Tokenized messages, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the Tokenized messages column\n",
    "df_train['Tokenized messages'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding New Featuers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding word count feature to the train dataset\n",
    "df_train['word count'] = df_train['message'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Part of Speech tag to Tokenized messages and assigning value to new [message POS] featue\n",
    "df_train['message POS'] = df_train['Tokenized messages'].apply(nltk.tag.pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning part of speech tag to tokens\n",
    "def POS_wordnet(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creting Stop Word removal feature\n",
    "def no_stop(row):\n",
    "    return[word for word in row if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying stop word removal function to Tokenized messages\n",
    "df_train['Tokenized messages'] = df_train['Tokenized messages'].apply(lambda x: no_stop(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [polyscimajor, epa, chief, doesnt, think, carb...\n",
       "1     [like, lack, evidence, anthropogenic, global, ...\n",
       "2     [researchers, say, three, years, act, climate,...\n",
       "3                 [pivotal, year, war, climate, change]\n",
       "4     [itsand, racist, sexist, climate, change, deny...\n",
       "5     [woh, read, whether, dont, believe, climate, c...\n",
       "6     [mike, pence, ’, believe, global, warming, smo...\n",
       "7     [six, big, things, today, fight, climate, chan...\n",
       "8     [yo, nephew, inconsolable, wants, die, old, ag...\n",
       "9       [offense…, like…, believe…, global, warming………]\n",
       "10    [shes, thinking, shes, going, die, husband, do...\n",
       "11    [hope, people, vocal, climate, change, also, p...\n",
       "12    [apercent, chance, avoiding, ‘, dangerous, ’, ...\n",
       "13    [oh, godtrumps, government, removes, climate, ...\n",
       "14    [fossil, fuel, giant, exxonmobil, ‘, misled, ’...\n",
       "15    [dont, wan, na, live, forever, –, nothing, cli...\n",
       "16    [issues, scrubbed, fromtoday, civil, rights, c...\n",
       "17    [elected, leaders, fail, approach, environment...\n",
       "18    [presidentelect, doesnt, believe, climate, cha...\n",
       "19    [calum, tweets, abt, reunitingish, w, cast, se...\n",
       "20    [c, mayors, representing, citizens, urged, g, ...\n",
       "21                 [climate, change, impacts, wildlife]\n",
       "22    [also, met, guy, let, us, truth, climate, chan...\n",
       "23    [scientists, say, climate, change, wiped, enti...\n",
       "24    [obama, raises, climate, change, better, vote,...\n",
       "25    [hate, say, mental, health, pretty, low, menu,...\n",
       "26     [bangladesh, confronting, climate, change, head]\n",
       "27    [hey, michaels, vetted, approved, marketbased,...\n",
       "28    [sally, kohn, ’, latest, evidence, climate, ch...\n",
       "29    [first, public, understands, climate, change, ...\n",
       "30      [scientists, denounce, climate, change, choice]\n",
       "31      [guide, global, warming, paris, pact, us, role]\n",
       "32    [atmospheric, rivers, fueled, climate, change,...\n",
       "33    [denying, climate, change, ignores, basic, sci...\n",
       "34    [bgrchina, practically, says, trump, lied, cli...\n",
       "35    [future, planet, stake, hillary, clinton, comb...\n",
       "36    [trumps, team, removed, climate, change, data,...\n",
       "37    [toxic, soils, aquifers, vast, amts, wastedwas...\n",
       "38    [america, climate, change, “, unproven, ”, peo...\n",
       "39    [’, dealt, simple, issues, like, climate, chan...\n",
       "40    [protested, suppo, climate, change, theand, pa...\n",
       "41    [climate, targets, nations, playing, long, gam...\n",
       "42    [trumps, climate, change, denial, could, cost,...\n",
       "43    [win, probability, bullshit, man, saw, nba, fi...\n",
       "44    [alaskan, tundra, filling, atmosphere, carbon,...\n",
       "45    [fromindian, environmentalist, calls, dicaprio...\n",
       "46    [carbon, tax, globalist, idea, enslave, worlds...\n",
       "47    [anyone, suppos, trumps, view, climate, change...\n",
       "48    [winds, close, tomph, area, afternoon, would, ...\n",
       "49    [world, food, supplies, risk, aschange, threat...\n",
       "50    [macron, charm, may, changed, trumps, mind, cl...\n",
       "51    [shes, thinking, shes, going, die, husband, do...\n",
       "52    [chris, initially, talked, climate, change, me...\n",
       "53    [approve, executive, orderis, due, sign, clima...\n",
       "54    [trump, doesnt, believe, global, warming, hes,...\n",
       "55    [irony, florida, state, danger, washed, away, ...\n",
       "56    [lmao, 😂, snowflakes, ❄️, complaining, snowfla...\n",
       "57    [one, arnold, schwarzeneggers, vehicles, whini...\n",
       "58    [calling, great, space, cylinder, save, global...\n",
       "59    [pollution, india, china, reached, stratospher...\n",
       "Name: Tokenized messages, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cheking the Tokenized messages column\n",
    "df_train['Tokenized messages'].head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assiging the WordNetLemmatizer to a variable [wnl]\n",
    "wnl = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lematizer function to apply to messages column\n",
    "def lemmatize_text(row):\n",
    "    return [wnl.lemmatize(word) for word in row] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing the Tokenized messages column and assigning the value to a new feature [lemma]\n",
    "df_train['lemma'] = df_train['Tokenized messages'].apply(lambda x: lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [polyscimajor, epa, chief, doesnt, think, carb...\n",
       "1    [like, lack, evidence, anthropogenic, global, ...\n",
       "2    [researcher, say, three, year, act, climate, c...\n",
       "3                [pivotal, year, war, climate, change]\n",
       "4    [itsand, racist, sexist, climate, change, deny...\n",
       "Name: lemma, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the lemma column\n",
    "df_train['lemma'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>Tokenized messages</th>\n",
       "      <th>word count</th>\n",
       "      <th>message POS</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
       "      <td>625221</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "      <td>99</td>\n",
       "      <td>[(polyscimajor, JJ), (epa, NN), (chief, NN), (...</td>\n",
       "      <td>[polyscimajor, epa, chief, doesnt, think, carb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>its not like we lack evidence of anthropogenic...</td>\n",
       "      <td>126103</td>\n",
       "      <td>[like, lack, evidence, anthropogenic, global, ...</td>\n",
       "      <td>61</td>\n",
       "      <td>[(its, PRP$), (not, RB), (like, IN), (we, PRP)...</td>\n",
       "      <td>[like, lack, evidence, anthropogenic, global, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>researchers say we have three years to act on ...</td>\n",
       "      <td>698562</td>\n",
       "      <td>[researchers, say, three, years, act, climate,...</td>\n",
       "      <td>83</td>\n",
       "      <td>[(researchers, NNS), (say, VBP), (we, PRP), (h...</td>\n",
       "      <td>[researcher, say, three, year, act, climate, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>was a pivotal year in the war on climate change</td>\n",
       "      <td>573736</td>\n",
       "      <td>[pivotal, year, war, climate, change]</td>\n",
       "      <td>47</td>\n",
       "      <td>[(was, VBD), (a, DT), (pivotal, JJ), (year, NN...</td>\n",
       "      <td>[pivotal, year, war, climate, change]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>itsand a racist sexist climate change denying ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>[itsand, racist, sexist, climate, change, deny...</td>\n",
       "      <td>75</td>\n",
       "      <td>[(itsand, VB), (a, DT), (racist, NN), (sexist,...</td>\n",
       "      <td>[itsand, racist, sexist, climate, change, deny...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid  \\\n",
       "0          1  polyscimajor epa chief doesnt think carbon dio...   625221   \n",
       "1          1  its not like we lack evidence of anthropogenic...   126103   \n",
       "2          2  researchers say we have three years to act on ...   698562   \n",
       "3          1    was a pivotal year in the war on climate change   573736   \n",
       "4          1  itsand a racist sexist climate change denying ...   466954   \n",
       "\n",
       "                                  Tokenized messages  word count  \\\n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...          99   \n",
       "1  [like, lack, evidence, anthropogenic, global, ...          61   \n",
       "2  [researchers, say, three, years, act, climate,...          83   \n",
       "3              [pivotal, year, war, climate, change]          47   \n",
       "4  [itsand, racist, sexist, climate, change, deny...          75   \n",
       "\n",
       "                                         message POS  \\\n",
       "0  [(polyscimajor, JJ), (epa, NN), (chief, NN), (...   \n",
       "1  [(its, PRP$), (not, RB), (like, IN), (we, PRP)...   \n",
       "2  [(researchers, NNS), (say, VBP), (we, PRP), (h...   \n",
       "3  [(was, VBD), (a, DT), (pivotal, JJ), (year, NN...   \n",
       "4  [(itsand, VB), (a, DT), (racist, NN), (sexist,...   \n",
       "\n",
       "                                               lemma  \n",
       "0  [polyscimajor, epa, chief, doesnt, think, carb...  \n",
       "1  [like, lack, evidence, anthropogenic, global, ...  \n",
       "2  [researcher, say, three, year, act, climate, c...  \n",
       "3              [pivotal, year, war, climate, change]  \n",
       "4  [itsand, racist, sexist, climate, change, deny...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the df_train dataset\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [polyscimajor, epa, chief, doesnt, think, carb...\n",
       "1    [like, lack, evidence, anthropogenic, global, ...\n",
       "2    [researcher, say, three, year, act, climate, c...\n",
       "3                [pivotal, year, war, climate, change]\n",
       "4    [itsand, racist, sexist, climate, change, deny...\n",
       "Name: lemma, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['lemma'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizing the lemma feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(text):\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(tokenizer = token, lowercase = False)\n",
    "vect_tmessages = vect.fit_transform(df_train['lemma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test splitting\n",
    "X = vect_tmessages\n",
    "Y = df_train['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the train test ratio and assiging X,y(train, test) values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=50)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "forest = RandomForestClassifier(n_estimators=100, random_state=50)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions using the random forest model\n",
    "prediction = forest.predict(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.23      0.36       336\n",
      "           0       0.58      0.31      0.40       547\n",
      "           1       0.68      0.91      0.78      2178\n",
      "           2       0.76      0.57      0.65       894\n",
      "\n",
      "    accuracy                           0.69      3955\n",
      "   macro avg       0.72      0.50      0.55      3955\n",
      "weighted avg       0.70      0.69      0.66      3955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print of the model performance\n",
    "print(metrics.classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
