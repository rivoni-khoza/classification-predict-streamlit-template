# Models Introduction

**Decision Tree:**

Decision tree builds classification or regression models in the form of a tree structure. It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes. A decision node has two or more branches. Leaf node represents a classification or decision. The topmost decision node in a tree which corresponds to the best predictor is called a root node. Decision trees can handle both categorical and numerical data.


**Linear SVM:**

Support Vector Machine is a linear model for classification and regression problems. It can solve linear and non-linear problems and work well for many practical problems. The idea of SVM is simple: The algorithm creates a line or a hyperplane which separates the data into classes. Support vectors are the data points that lie closest to the decision surface (or hyperplane).
SVMs maximize the margin around the separating hyperplane.
The decision function is fully specified by a subset of training samples, the support vectors.


**Logistic Regression:** 

Logistic regression is a classification algorithm used to assign observations to a discrete set of classes.Logistic Regression  algorithms are used for the classification problems, it is a predictive analysis algorithm and based on the concept of probability. Logistic Regression uses a complex cost function, this cost function can be defined as the ‘Sigmoid function’ or also known as the ‘logistic function’ instead of a linear function. The Sigmoid function maps any real value into another value between 0 and 1. In machine learning, we use sigmoid to map predictions to probabilities.
